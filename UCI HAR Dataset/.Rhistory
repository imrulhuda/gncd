fileurl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileurl, destfile="./data/microdata.csv", method="curl")
download.file(fileUrl, destfile="./data/microdata.csv")
download.file(fileurl, destfile="./data/microdata.csv")
download.file(fileurl, destfile="./Getting and Cleaning Data/microdata.csv")
microData <- read.table("./Getting and Cleaning Data/microdata.csv", sep=",", header=TRUE)
sum(!is.na(microData$VAL[microData$VAL==24]))
sum(!is.na(microData$VAL==24))
microData$FES
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl, destfile="./Getting and Cleaning Data/nga.xlsx")
library(xlsx)
install.package("xlsx")
install.packages("xlsx")
library(xlsx)
Sys.setenv(Java_Home="")
library(xlsx)
install.packages("openxlsx")
library("openxlsx")
colIndex<-7:15
rowIndex<-18:23
dat <- read.xlsx("./Getting and Cleaning Data/nga.xlsx", sheetIndex=1, header=TRUE, colIndex=colIndex, rowIndex=rowIndex)
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
library(xml)
install.packages("XML")
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
rootNode <- xmlRoot(doc)
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destfile="./Getting and Cleaning Data/microdata3.csv")
DT <- fread("./Getting and Cleaning Data/microdata3.csv")
DT <- fread("./Getting and Cleaning Data/microdata3.csv")
install.packages("Data.table")
y
install.packages("data.table")
DT <- fread("./Getting and Cleaning Data/microdata3.csv")
#Part 1 - Merging Training and Test
> setwd("G:/Ayon/Desktop/Data Science/Getting and Cleaning Data/Project/UCI HAR Dataset")
> tmp1 <- read.table("train/X_train.txt")
> tmp2 <- read.table("test/X_test.txt")
> X <- rbind(tmp1, tmp2)
> tmp1 <- read.table("train/subject_train.txt")
> tmp2 <- read.table("test/subject_test.txt")
> S <- rbind(tmp1, tmp2)
> tmp1 <- read.table("train/y_train.txt")
> tmp2 <- read.table("test/y_test.txt")
> Y <- rbind(tmp1, tmp2)
#Part 2 - Extracting Mean and SD from each observation
> features <- read.table("features.txt")
> indices_of_good_features <- grep("-mean\\(\\)|-std\\(\\)", features[, 2])
> X <- X[, indices_of_good_features]
> names(X) <- features[indices_of_good_features, 2]
> names(X) <- gsub("\\(|\\)", "", names(X))
> names(X) <- tolower(names(X))
#Part 3 - Naming the Activities
> activities <- read.table("activity_labels.txt")
> activities[, 2] = gsub("_", "", tolower(as.character(activities[, 2])))
> Y[,1] = activities[Y[,1], 2]
> names(Y) <- "activity"
#Part 4 - Appropriate Lebeling
> names(S) <- "subject"
> cleaned <- cbind(S, Y, X)
> write.table(cleaned, "merged_clean_data.txt")
#Part 1 - Merging Training and Test
setwd("G:/Ayon/Desktop/Data Science/Getting and Cleaning Data/Project/UCI HAR Dataset")
tmp1 <- read.table("train/X_train.txt")
tmp2 <- read.table("test/X_test.txt")
X <- rbind(tmp1, tmp2)
tmp1 <- read.table("train/subject_train.txt")
tmp2 <- read.table("test/subject_test.txt")
S <- rbind(tmp1, tmp2)
tmp1 <- read.table("train/y_train.txt")
tmp2 <- read.table("test/y_test.txt")
Y <- rbind(tmp1, tmp2)
#Part 2 - Extracting Mean and SD from each observation
features <- read.table("features.txt")
indices_of_good_features <- grep("-mean\\(\\)|-std\\(\\)", features[, 2])
X <- X[, indices_of_good_features]
names(X) <- features[indices_of_good_features, 2]
names(X) <- gsub("\\(|\\)", "", names(X))
names(X) <- tolower(names(X))
#Part 3 - Naming the Activities
activities <- read.table("activity_labels.txt")
activities[, 2] = gsub("_", "", tolower(as.character(activities[, 2])))
Y[,1] = activities[Y[,1], 2]
names(Y) <- "activity"
#Part 4 - Appropriate Lebeling
names(S) <- "subject"
cleaned <- cbind(S, Y, X)
write.table(cleaned, "merged_clean_data.txt")
uniqueSubjects = unique(S)[,1]
numSubjects = length(unique(S)[,1])
numActivities = length(activities[,1])
numCols = dim(cleaned)[2]
result = cleaned[1:(numSubjects*numActivities), ]
result = cleaned[1:(numSubjects*numActivities), ]
row = 1
for (s in 1:numSubjects) {
for (a in 1:numActivities) {
result[row, 1] = uniqueSubjects[s]
result[row, 2] = activities[a, 2]
tmp <- cleaned[cleaned$subject==s & cleaned$activity==activities[a, 2], ]
result[row, 3:numCols] <- colMeans(tmp[, 3:numCols])
row = row+1
}
}
write.table(result, "data_set_with_the_averages.txt")
write.table(result, "csv")
write.table(result, "data_set_with_the_averages.csv")
